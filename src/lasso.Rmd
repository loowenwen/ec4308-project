---
title: "lasso"
author: "Abigail"
date: "2025-10-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load libraries}
library(glmnet)
library(hdm)
library(tidyverse)
```

```{r helper functions}

RMSE <- function(pred, truth){ 
  return(sqrt(mean((truth - pred)^2)))
}

MSE <- function(pred, truth){ 
  return(mean((truth - pred)^2)) 
}

#scale a df using min-max from training data
minmax_scale <- function(df) {
  mins <- apply(df, 2, min, na.rm = TRUE)
  maxs <- apply(df, 2, max, na.rm = TRUE)
  
  scaled <- sweep(df, 2, mins, "-")
  scaled <- sweep(scaled, 2, maxs - mins, "/")
  
  list(scaled = scaled, mins = mins, maxs = maxs)
}

# APPLY previously fitted min-max parameters to a new dataset
minmax_apply <- function(df, mins, maxs) {
  scaled <- sweep(df, 2, mins, "-")
  scaled <- sweep(scaled, 2, maxs - mins, "/")
  return(scaled)
}

#Inverse transform (to get back actual values)
minmax_unscale <- function(scaled, mins, maxs) {
  unscaled <- sweep(scaled, 2, maxs - mins, "*")
  unscaled <- sweep(unscaled, 2, mins, "+")
  return(unscaled)
}
  
```


## Split Training and Validation Set, Test Set

```{r set}
# minmax scaling on all predictors and Y
scaled_part <- minmax_scale(Z_8[, !(names(Z_8) %in% c("sasdate"))])
df_scaled <- cbind(sasdate = Z_8$sasdate, scaled_part$scaled)

#subsetting training and validation set
df_train <- df_scaled %>%
  mutate(sasdate = as.Date(sasdate, format = "%m/%d/%Y")) %>%
  filter(year(sasdate) < 2020)
df_test <- df_scaled %>%
  mutate(sasdate = as.Date(sasdate, format = "%m/%d/%Y")) %>%
  filter(year(sasdate)> 2019)

df_train_nodate = df_train %>%
  select(-sasdate)
df_test_nodate = df_test %>%
  select(-sasdate)

#x and y var
Y_train <- df_train[,"CPIAUCSL"]
Y_test <- df_test[,"CPIAUCSL"]
X_train <- df_train %>% select(-c(sasdate, CPIAUCSL))
X_test <- df_test %>% select(-c(sasdate, CPIAUCSL))

#validation set
nprev=60 #number of out-of-sample observations (test window )
Y_validation = tail(Y_train,nprev) 
X_validation = tail(X_train,nprev)

# actual training set - validation
Y_train_smaller = Y_train[1:(length(Y_train) - 60)]
X_train_smaller = X_train[1:(length(X_train) - 60)]
```


## LASSO

```{r plug in lambda}
# define horizons of interest
horizons <- c(1,3,6,9,12)

# store results
rmse_vec <- numeric(length(horizons))
mse_vec <- numeric(length(horizons))
names(rmse_vec) <- paste0("h", horizons)
names(mse_vec) <- paste0("h", horizons)
pred_list <- list()

for(i in seq_along(horizons)){
  h <- horizons[i]
  
  # shifted target for training (x1t,x2t...-> y(t+h))
  Y_train_h <- dplyr::lead(Y_train, h)
  valid_idx <- !is.na(Y_train_h)
  X_train_h <- as.matrix(X_train[valid_idx, ])
  Y_train_h <- Y_train_h[valid_idx]
  
  # fit rlasso
  fit <- rlasso(X_train_h, Y_train_h, post=FALSE)
  
  # shifted target for test
  Y_test_h <- dplyr::lead(Y_test, h) %>% na.omit()
  X_test_h <- as.matrix(X_test[1:length(Y_test_h), ])
  
  # predict
  yhat <- predict(fit, newdata = X_test_h)
  pred_list[[i]] <- yhat
  
  # compute MSE and RMSE
  mse <- MSE(yhat, Y_test_h)
  mse_vec[i] <- mse
  rmse_vec[i] <- sqrt(mse)
}

mse_vec
rmse_vec
```

```{r plug in lambda, post-lasso}

# store results
rmse_vec2 <- numeric(length(horizons))
mse_vec2 <- numeric(length(horizons))
names(rmse_vec2) <- paste0("h", horizons)
names(mse_vec2) <- paste0("h", horizons)
pred_list2 <- list()

for(i in seq_along(horizons)){
  h <- horizons[i]
  
  # shifted target for training (x1t,x2t...-> y(t+h))
  Y_train_h <- dplyr::lead(Y_train, h)
  valid_idx <- !is.na(Y_train_h)
  X_train_h <- as.matrix(X_train[valid_idx, ])
  Y_train_h <- Y_train_h[valid_idx]
  
  # fit rlasso
  fit <- rlasso(X_train_h, Y_train_h, post=TRUE)
  
  # shifted target for test
  Y_test_h <- dplyr::lead(Y_test, h) %>% na.omit()
  X_test_h <- as.matrix(X_test[1:length(Y_test_h), ])
  
  # predict
  yhat <- predict(fit, newdata = X_test_h)
  pred_list2[[i]] <- yhat
  
  # compute MSE and RMSE
  mse <- MSE(yhat, Y_test_h)
  mse_vec2[i] <- mse
  rmse_vec2[i] <- sqrt(mse)
}

mse_vec2
rmse_vec2
```


```{r lasso with bic}
rmse_vec3 <- numeric(length(horizons))
mse_vec3 <- numeric(length(horizons))

# setting user-defined grid
# grid = 10^seq(10, -2, length = 100)

# function to choose lambda via BIC 
choose_lambda_bic <- function(X, Y, lambda_grid) {
  n <- nrow(X)
  fit <- glmnet(as.matrix(X), as.numeric(Y), alpha = 1, lambda = lambda_grid, standardize = FALSE)
  
  yhat <- predict(fit, as.matrix(X)) # predicted values
  
  # compute bic
  rss <- colSums((yhat - as.numeric(Y))^2)
  df <- fit$df
  bic <- n * log(rss / n) + df * log(n)
  
  # choose best lambda
  plot(bic~lambda_grid)
  best_lambda <- lambda_grid[which.min(bic)]
  return(best_lambda)
}

# find best lambda for all horizons FIND GOOD GRID PLSSSSS
lambda_grid <- 10^seq(-4, 0.5, length.out = 100)

best_lambdas <- c()

for (h in horizons) {
  Y_train_h <- Y_train[(1 + h):length(Y_train)]
  X_train_h <- X_train[1:(nrow(X_train) - h), ]
  
  best_lambda <- choose_lambda_bic(X_train_h, Y_train_h, lambda_grid)
  best_lambdas <- c(best_lambdas, best_lambda)
  
  cat("h =", h, ": best lambda (BIC) =", round(best_lambda, 6), "\n")
  
  # fit models with best lambda
  fit <- glmnet(as.matrix(X_train_h), as.numeric(Y_train_h),
                alpha = 1, lambda = best_lambda, standardize = FALSE)
  
  # predict on test set
  # align test X with horizon h if needed
  Y_test_h <- Y_test[(1 + h):length(Y_test)] #only start h steps after the first ytest obs
  X_test_h <- X_test[1:(nrow(X_test) - h), ] #dont use the last h X obs
  yhat <- predict(fit, as.matrix(X_test_h))

  rmse <- RMSE(yhat, Y_test_h)
  mse  <- MSE(yhat, Y_test_h)
  mse_vec3[i] <- mse
  rmse_vec3[i] <- rmse
}

mse_vec3
rmse_vec3

```

```{r lasso with rolling window??}

```


