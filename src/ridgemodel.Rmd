---
title: "ridge_model"
author: "MV"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r helper (same as LASSO)}

RMSE <- function(pred, truth){ 
  return(sqrt(mean((truth - pred)^2)))
}

MSE <- function(pred, truth){ 
  return(mean((truth - pred)^2)) 
}

#scale a df using min-max from training data
minmax_scale <- function(df) {
  mins <- apply(df, 2, min, na.rm = TRUE)
  maxs <- apply(df, 2, max, na.rm = TRUE)
  
  scaled <- sweep(df, 2, mins, "-")
  scaled <- sweep(scaled, 2, maxs - mins, "/")
  
  list(scaled = scaled, mins = mins, maxs = maxs)
}

# APPLY previously fitted min-max parameters to a new dataset
minmax_apply <- function(df, mins, maxs) {
  scaled <- sweep(df, 2, mins, "-")
  scaled <- sweep(scaled, 2, maxs - mins, "/")
  return(scaled)
}

#Inverse transform (to get back actual values)
minmax_unscale <- function(scaled, mins, maxs) {
  unscaled <- sweep(scaled, 2, maxs - mins, "*")
  unscaled <- sweep(unscaled, 2, mins, "+")
  return(unscaled)
}
  
```


##using MARX matrix##
```{r }

X <- Z_16[, !(names(Z_16) %in% c("sasdate", "CPIAUCSL"))]
Y <- Z_16$CPIAUCSL
dates <- Z_16$sasdate

train_idx <- year(dates) < 2020
test_idx  <- year(dates) >= 2020

X_train <- X[train_idx, ]
X_test  <- X[test_idx, ]
Y_train <- Y[train_idx]
Y_test  <- Y[test_idx]


X_train_centered <- scale(X_train)               # centres & scales
X_train_mean <- attr(X_train_centered, "scaled:center")
X_train_sd   <- attr(X_train_centered, "scaled:scale")


X_test_centered <- sweep(X_test, 2, X_train_mean, "-")
X_test_centered <- sweep(X_test_centered, 2, X_train_sd,   "/")


Y_train_mean <- mean(Y_train)
Y_train_c    <- Y_train - Y_train_mean
Y_test_c     <- Y_test  - Y_train_mean


nprev <- 60
X_val   <- tail(X_train_centered, nprev)
Y_val   <- tail(Y_train_c,       nprev)

X_train_final <- head(X_train_centered, -nprev)
Y_train_final <- head(Y_train_c,       -nprev)


X_train_mat <- as.matrix(X_train_final)
X_val_mat   <- as.matrix(X_val)
X_test_mat  <- as.matrix(X_test_centered)

Y_train_vec <- as.numeric(Y_train_final)
Y_val_vec   <- as.numeric(Y_val)
Y_test_vec  <- as.numeric(Y_test_c)
```


```{r}

# alpha = 0 → pure ridge
cv_ridge <- cv.glmnet(
  x = X_train_mat,
  y = Y_train_vec,
  alpha = 0,
  nfolds = 10,                # you can keep your own validation set if you like
  standardize = FALSE        # we already standardised manually
)

pred_test_c <- predict(cv_ridge, X_test_mat, s = best_lambda, type = "response")[,1]

# Bring predictions back to the original Y scale
pred_test <- pred_test_c + Y_train_mean
Y_test_original <- Y_test          # already in original units

# 5a – Predicted vs Actual (original scale)
plot(Y_test_original, pred_test,
     xlab = "Actual", ylab = "Predicted",
     main = "Ridge: Predicted vs Actual (fixed)",
     pch = 19, col = "steelblue")
abline(0, 1, col = "red", lwd = 2)

# 5b – R²
rsq <- cor(Y_test_original, pred_test)^2
cat(sprintf("Test R² = %.4f\n", rsq))

# 5c – Coefficient path (just to confirm shrinkage is sane)
plot(cv_ridge$glmnet.fit, xvar = "lambda", label = TRUE)
abline(v = log(best_lambda), col = "red", lty = 2)



```

##add lagged Y terms?##
```{r}








```